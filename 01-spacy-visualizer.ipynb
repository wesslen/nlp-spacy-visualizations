{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f907e94d-7342-44dd-bdc1-943673e871b1",
   "metadata": {},
   "source": [
    "## Visualizing Text with spaCy and other NLP packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0889e66b-ff31-4a66-9eb8-c817b35b8786",
   "metadata": {},
   "source": [
    "[spaCy](https://spacy.io/) is a free, open-source library for advanced Natural Language Processing (NLP) in Python. It’s designed specifically for production use and helps you build applications that process and “understand” large volumes of text. It can be used to build information extraction or natural language understanding systems.\n",
    "\n",
    "spaCy is created by [Explosion AI](https://explosion.ai/), which also makes [Prodigy](https://prodi.gy/), which is a scriptable annotation tool for creating training and evaluation data for machine learning.\n",
    "\n",
    "This tutorial won't have enough time to go through everything about spaCy -- instead, I'll show you a few examples and also provide some helpful visualizer tools that are part of spaCy's universe.\n",
    "\n",
    "If you're interested in learning more about spaCy, I recommend spaCy's [free online course](https://course.spacy.io/en) as well as its [spaCy 101 documentation](https://spacy.io/usage/spacy-101).\n",
    "\n",
    "To begin, I'll assume you'll have created a virtual environment and installed the needed packages provided in the [README](README.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f2d648-f468-4062-b6b2-8c82dbf107cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/Downloads/nlp-spacy-visualizations/.env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Biden PERSON\n",
      "the United States GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"Joe Biden is the president of the United States.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "for entity in doc.ents:\n",
    "    print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0c60ab-9c23-4db8-93e2-b6bf1b03716e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb74ecb-75fc-4542-9813-c347d909d764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Joe Biden\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is the president of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19c5f7d-d7df-443c-be6d-26ce30564dfb",
   "metadata": {},
   "source": [
    "Or we can use it for its dependency parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5d3f52f-c84b-487a-8178-c1f0d7dcb40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"bdf88be0ec0d4340874d754c6497b620-0\" class=\"displacy\" width=\"1625\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Joe</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Biden</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">president</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">United</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">States.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bdf88be0ec0d4340874d754c6497b620-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bdf88be0ec0d4340874d754c6497b620-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bdf88be0ec0d4340874d754c6497b620-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bdf88be0ec0d4340874d754c6497b620-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bdf88be0ec0d4340874d754c6497b620-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bdf88be0ec0d4340874d754c6497b620-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bdf88be0ec0d4340874d754c6497b620-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bdf88be0ec0d4340874d754c6497b620-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bdf88be0ec0d4340874d754c6497b620-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bdf88be0ec0d4340874d754c6497b620-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bdf88be0ec0d4340874d754c6497b620-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,89.5 1445.0,89.5 1445.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bdf88be0ec0d4340874d754c6497b620-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bdf88be0ec0d4340874d754c6497b620-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,177.0 1440.0,177.0 1440.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bdf88be0ec0d4340874d754c6497b620-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bdf88be0ec0d4340874d754c6497b620-0-7\" stroke-width=\"2px\" d=\"M945,264.5 C945,2.0 1450.0,2.0 1450.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bdf88be0ec0d4340874d754c6497b620-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,266.5 L1458.0,254.5 1442.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec8281-8740-4978-af23-080491fa1693",
   "metadata": {},
   "source": [
    "## Topic modeling with BERTopic\n",
    "\n",
    "Analyzing new text datasets is challenging because it's hard to know what is the right question to ask. This is where exploratory analysis can help. A popular NLP technique for exploratory analysis is [topic modeling](https://en.wikipedia.org/wiki/Topic_model).\n",
    "\n",
    "Topic modeling is (typically) is set up as unsupervised machine learning where the goal is to find hidden or latent patterns in datasets that can be interpreated as topics.\n",
    "\n",
    "We'll use a more modern version of topic modeling using BERTopic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f495d8a-8b69-4eba-84fb-b07ceb753a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"ready.csv\")\n",
    "\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e019ebea-c7ca-4b10-8c33-71576e7b2917",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertopic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_20newsgroups\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbertopic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mumap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UMAP\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Prepare embeddings\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bertopic'"
     ]
    }
   ],
   "source": [
    "#from sklearn.datasets import fetch_20newsgroups\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "\n",
    "# Prepare embeddings\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(texts, show_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ed71d0-a22a-4530-86ab-94c21df7ede2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This BERTopic instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/explosion/prodigy-support-exploratory/.env/lib/python3.8/site-packages/bertopic/_bertopic.py:1539\u001b[0m, in \u001b[0;36mBERTopic.visualize_topics\u001b[0;34m(self, topics, top_n_topics, width, height)\u001b[0m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_topics\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1509\u001b[0m                      topics: List[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1510\u001b[0m                      top_n_topics: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1511\u001b[0m                      width: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m650\u001b[39m,\n\u001b[1;32m   1512\u001b[0m                      height: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m650\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure:\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;124;03m\"\"\" Visualize topics, their sizes, and their corresponding words\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m \n\u001b[1;32m   1515\u001b[0m \u001b[38;5;124;03m    This visualization is highly inspired by LDAvis, a great visualization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1539\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m plotting\u001b[38;5;241m.\u001b[39mvisualize_topics(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1541\u001b[0m                                      topics\u001b[38;5;241m=\u001b[39mtopics,\n\u001b[1;32m   1542\u001b[0m                                      top_n_topics\u001b[38;5;241m=\u001b[39mtop_n_topics,\n\u001b[1;32m   1543\u001b[0m                                      width\u001b[38;5;241m=\u001b[39mwidth,\n\u001b[1;32m   1544\u001b[0m                                      height\u001b[38;5;241m=\u001b[39mheight)\n",
      "File \u001b[0;32m~/Desktop/explosion/prodigy-support-exploratory/.env/lib/python3.8/site-packages/bertopic/_utils.py:70\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(topic_model)\u001b[0m\n\u001b[1;32m     66\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m instance is not fitted yet. Call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappropriate arguments before using this estimator.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m topic_model\u001b[38;5;241m.\u001b[39mtopics_ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mtype\u001b[39m(topic_model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mValueError\u001b[0m: This BERTopic instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1850163-3850-4550-92d9-8dbe37677d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Train BERTopic\n",
    "topic_model = BERTopic().fit(texts, embeddings)\n",
    "\n",
    "# Run the visualization with the original embeddings\n",
    "topic_model.visualize_documents(texts, embeddings=embeddings)\n",
    "\n",
    "# Reduce dimensionality of embeddings, this step is optional but much faster to perform iteratively:\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "topic_model.visualize_documents(texts, reduced_embeddings=reduced_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf363155-0a47-4c9d-8037-2c1ae6f990a1",
   "metadata": {},
   "source": [
    "## whatlies\n",
    "\n",
    "A major advance in NLP over the last 10 years has been [word embedding models](https://ruder.io/word-embeddings-1/). These provide a way to quantify word meaning. Embeddings are typically \"pre-trained\" by learning the context of words that tend to co-occur. A classic example is [word2vec](https://jalammar.github.io/illustrated-word2vec/). One example of this is in [Tensorboard Projector](https://projector.tensorflow.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619d932f-6cd5-4e0d-9f9a-ba9198de40c6",
   "metadata": {},
   "source": [
    "The [`whatlies`](https://github.com/koaning/whatlies) package tries to help you to understand. \"What lies in word embeddings?\"\n",
    "\n",
    "This small library offers tools to make visualisation easier of both word embeddings as well as operations on them. This should be considered an experimental project. This library will allow you to make visualisations of transformations of word embeddings. Some of these transformations are linear algebra operators.\n",
    "\n",
    "The library uses [`altair`](https://altair-viz.github.io/), which is a Python package for [Vega-Lite](https://vega.github.io/vega-lite/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7fe5700-ab86-496b-b848-fb394c0b5527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryan/Downloads/nlp-spacy-visualizations/.env/lib/python3.9/site-packages/altair/utils/core.py:317: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col_name, dtype in df.dtypes.iteritems():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-dc4da4e322fb4cd7ba48d106190e0498\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-dc4da4e322fb4cd7ba48d106190e0498\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-dc4da4e322fb4cd7ba48d106190e0498\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 60}, \"encoding\": {\"color\": {\"field\": \"\", \"legend\": null, \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"name\", \"type\": \"nominal\"}, {\"field\": \"original\", \"type\": \"nominal\"}], \"x\": {\"axis\": {\"title\": \"man\"}, \"field\": \"x_axis\", \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"woman\"}, \"field\": \"y_axis\", \"type\": \"quantitative\"}}, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"title\": \"man vs. woman\"}, {\"mark\": {\"type\": \"text\", \"color\": \"black\", \"dx\": -15, \"dy\": 3}, \"encoding\": {\"text\": {\"field\": \"original\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x_axis\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y_axis\", \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-f2e10597ff16fad987bcc577821bfc98\"}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-f2e10597ff16fad987bcc577821bfc98\": [{\"x_axis\": 0.7492215037345886, \"y_axis\": 0.8316355347633362, \"name\": \"cat\", \"original\": \"cat\"}, {\"x_axis\": 0.585007905960083, \"y_axis\": 0.8169962167739868, \"name\": \"dog\", \"original\": \"dog\"}, {\"x_axis\": 0.4379595220088959, \"y_axis\": 0.6901183724403381, \"name\": \"fish\", \"original\": \"fish\"}, {\"x_axis\": 0.3296080231666565, \"y_axis\": 0.4718848168849945, \"name\": \"kitten\", \"original\": \"kitten\"}, {\"x_axis\": 1.0, \"y_axis\": 0.8783338069915771, \"name\": \"man\", \"original\": \"man\"}, {\"x_axis\": 0.6979486346244812, \"y_axis\": 1.0, \"name\": \"woman\", \"original\": \"woman\"}, {\"x_axis\": 0.6561866402626038, \"y_axis\": 0.7965781688690186, \"name\": \"king\", \"original\": \"king\"}, {\"x_axis\": 0.5857027769088745, \"y_axis\": 0.5498035550117493, \"name\": \"queen\", \"original\": \"queen\"}, {\"x_axis\": 0.735887885093689, \"y_axis\": 0.8110100626945496, \"name\": \"doctor\", \"original\": \"doctor\"}, {\"x_axis\": 0.6829949617385864, \"y_axis\": 0.7493648529052734, \"name\": \"nurse\", \"original\": \"nurse\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from whatlies import EmbeddingSet\n",
    "from whatlies.language import SpacyLanguage\n",
    "\n",
    "lang = SpacyLanguage(\"en_core_web_sm\")\n",
    "words = [\"cat\", \"dog\", \"fish\", \"kitten\", \"man\", \"woman\",\n",
    "         \"king\", \"queen\", \"doctor\", \"nurse\"]\n",
    "\n",
    "emb = EmbeddingSet(*[lang[w] for w in words])\n",
    "emb.plot_interactive(x_axis=emb[\"man\"], y_axis=emb[\"woman\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c367fb-995e-4ed3-97c3-6f805f9ba8a0",
   "metadata": {},
   "source": [
    "## `bulk`\n",
    "\n",
    "[`bulk`](https://github.com/koaning/bulk) is a quick developer tool to apply some bulk labels. Given a prepared dataset with 2d embeddings it can generate an interface that allows you to quickly add some bulk, albeit less precice, annotations."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ed8364d-070a-4368-bdcd-61d344b5c194",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from umap import UMAP\n",
    "\n",
    "# pip install \"embetter[text]\"\n",
    "from embetter.text import SentenceEncoder\n",
    "\n",
    "# Build a sentence encoder pipeline with UMAP at the end.\n",
    "text_emb_pipeline = make_pipeline(\n",
    "  SentenceEncoder('all-MiniLM-L6-v2'),\n",
    "  UMAP()\n",
    ")\n",
    "\n",
    "# Calculate embeddings \n",
    "X_tfm = text_emb_pipeline.fit_transform(texts)\n",
    "\n",
    "# Write to disk. Note! Text column must be named \"text\"\n",
    "df = pd.DataFrame({\"text\": texts})\n",
    "df['x'] = X_tfm[:, 0]\n",
    "df['y'] = X_tfm[:, 1]\n",
    "df.to_csv(\"ready.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5318147c-b636-4be4-be11-040a9c85f534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to serve `bulk` over at http://localhost:5006/.\n",
      "404 GET /favicon.ico (::1) 0.29ms\n",
      "^C\n",
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!python -m bulk text ready.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ba5d237-067d-4150-a0f2-213a7757e7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "About to serve `bulk` over at http://localhost:5006/.\n",
      "^C\n",
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!python -m bulk text ready.csv --keywords \"coffee,pizza,haircuts\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2922c6-18ec-4787-ad85-31873867761b",
   "metadata": {},
   "source": [
    "If you're interested in learning more, check out Vincent's [Bulk Labeling and Prodigy video](https://www.youtube.com/embed/gDk7_f3ovIk) or the related video on [Bulk Labeling for Images](https://www.youtube.com/watch?v=DmH3JmX3w2I&feature=emb_rel_pause)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
